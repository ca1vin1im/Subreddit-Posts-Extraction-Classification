{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "405d3fc2",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Part 1 — Subreddit Posts Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab382b1",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199a028",
   "metadata": {},
   "source": [
    "[*Twitch*](https://www.twitch.tv/p/en/about/) is an American interactive livestreaming service for content spanning gaming, entertainment, sports, music, and more.\n",
    "\n",
    "Similar to many other online social platforms, we are always looking for new ways to better engage our users, expands our products and service offerings, thereby increasing customer stickiness through greater user experience and improving both top and bottom lines.\n",
    "\n",
    "_**Why Gaming?**_<br>\n",
    "- **Video Gaming Industry**: ~$178.73 Billion in 2021 (increase of 14.4% from 2020) ([*source*](https://www.wepc.com/news/video-game-statistics/))\n",
    "\n",
    "- **Global eSports market**: ~$1.08 Billion in 2021 (increase of ~50% from 2020) ([*source*](https://www.statista.com/statistics/490522/global-esports-market-revenue/))\n",
    "\n",
    "- **eSports industry's global market revenue**: Forecasted to grow to as much as $1.62 Billion in 2024. \n",
    "\n",
    "- China alone accounts for almost 1/5 of this market. \n",
    "\n",
    "In recent months, we started a pilot program with a subset of our most active users by availing them to a new beta forum that has sparked many discussions amongst our gaming users.\n",
    "\n",
    "This has resulted in hightened traffic with frequent posts and comments updates daily. Our business development and marketing counterparts also realised these gaming users are predominantly focusing on 2 games, namely [***Dota 2***](https://www.dota2.com/home) and [***League of Legends (LoL)***](https://leagueoflegends.com). \n",
    "\n",
    "Our business development and marketing colleagues see great potential in tapping on this group of active gamers and the associated data. However, since there is merely 1 single beta gaming forum thread, users have to sieve through multiple posts to find topics that interest or are relevant to them, resulting in potential poor user experience. Additionally, it would be more effective and efficient to target each game's user base separately by designing sales and marketing campaigns that better meet the corresponding user base's needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c20d0",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe024c",
   "metadata": {},
   "source": [
    "- Our business development and marketing colleagues have requested for us, the Data Science team, to design an **AI model** that **correctly classifies posts** in the 1 single beta gaming forum thread into 2 separate threads, 1 for Dota 2 and another for League of Legends (LoL), with an **accuracy of at least 85%** and **Top 10 Predictors for each subreddit** thereby improving user experience and increasing ease of designing more targeted sales and marketing campaigns that better meet the corresponding user base's needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d69d23b",
   "metadata": {},
   "source": [
    "**Datasets to be scraped:** _(Refer to **Part 2 — Subreddit Posts Classification** for Data cleaning and Modeling code, etc.)_\n",
    " - **`dota2_raw.csv`**: Dota 2 dataset\n",
    " - **`lol_raw.csv`**: League of Legends (LoL) dataset\n",
    "<br>\n",
    "\n",
    "**Brief Description of Datasets selected:** \n",
    "- The 2 datasets above, each comprising 4,000 records, were scrapped using the code below with the [*pushshift API*](https://github.com/pushshift/api) from subreddits: \n",
    "  - [***r/DotA2***](https://www.reddit.com/r/DotA2/); and \n",
    "  - [***r/leagueoflegends***](https://www.reddit.com/r/leagueoflegends/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019391f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from random import randrange\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf4d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function extract posts from subreddit in multiples of 100 posts per request\n",
    "\n",
    "def extract(subreddit, n):\n",
    "    \n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    \n",
    "    # Create dataframe for storing posts\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Loop n times to retreive the required number of posts (100 posts per request)\n",
    "    #     i.e. n = 40 extracts 4000 posts in total\n",
    "    # Append data extracted from each round to the dataframe\n",
    "    for i in range(n):\n",
    "        \n",
    "        if i == 0:    # For the first loop only, use current time\n",
    "            params = {'subreddit': subreddit, 'size': 100}\n",
    "        else:         # For subsequent loops, use timestamp in post at last data row based on the 'created_utc'\n",
    "            params = {'subreddit': subreddit, 'size': 100, 'before': last_row_timestamp}\n",
    "            \n",
    "        result = requests.get(url, params)\n",
    "        data = pd.DataFrame(result.json()['data'])\n",
    "        df = df.append(data, ignore_index = True)\n",
    "        \n",
    "        # Initialize next extraction loop using timestamp in post at last data row based on the 'created_utc'\n",
    "        last_row_timestamp = df['created_utc'].iloc[-1]\n",
    "        \n",
    "        # Set a timer before next iteration\n",
    "        time.sleep(randrange(1, 5))\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to compare all rows in dataset to check for duplicated rows\n",
    "def duplicate(df):\n",
    "    \n",
    "    if len(df[df.duplicated()]) == 0:\n",
    "        return \"This dataset has no duplicated rows.\"\n",
    "    else:\n",
    "        print(f'Duplicated row(s):\\n {df[df.duplicated()]}')  # List duplicated row(s) in dataset, if any\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d299c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 87)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract 4000 rows of posts from \"Dota 2\" subreddit\n",
    "# https://www.reddit.com/r/DotA2/\n",
    "dota2 = extract('DotA2', 40)\n",
    "dota2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d89159a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dota2 dataframe (Raw version) as a csv file into the same folder as the original data files\n",
    "dota2.to_csv('../datasets/dota2_raw.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231baf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 80)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract 4000 rows of posts from \"League of Legends\" subreddit\n",
    "# https://www.reddit.com/r/leagueoflegends/\n",
    "lol = extract('leagueoflegends', 40)\n",
    "lol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26d24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lol dataframe (Raw version) as a csv file into the same folder as the original data files\n",
    "lol.to_csv('../datasets/lol_raw.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated row in dota2 dataset except for the first occurrence & update index column of dataset accordingly\n",
    "dota2.drop_duplicates(inplace = True, ignore_index = True)\n",
    "dota2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dota2 dataframe as a csv file into the same folder as the original data files\n",
    "dota2.to_csv('../datasets/dota2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77062275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated row in lol dataset except for the first occurrence & update index column of dataset accordingly\n",
    "lol.drop_duplicates(inplace = True, ignore_index = True)\n",
    "lol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lol dataframe as a csv file into the same folder as the original data files\n",
    "lol.to_csv('../datasets/lol.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d44bd",
   "metadata": {},
   "source": [
    "### Refer to Part 2 — Subreddit Posts Classification for Data cleaning and Modeling code, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
